{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMZLV6MthkFRmutKmDe7wvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DajanaSanchez/BirdMigrationClimateAnalysis/blob/main/Captone_Bird.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX3AAv6jCeO0",
        "outputId": "e6402661-ad2f-4203-87b4-a48a8c36e142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/IT Capstone'\n",
        "\n",
        "%ls -ltra\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT1ABicwDER6",
        "outputId": "2a2ad627-0ee6-4958-e0ac-2029ebb1f535"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/IT Capstone\n",
            "total 21669251\n",
            "-rw------- 1 root root  1506197081 Jan 29 01:46 ebd_US_rthhum_197401_202412_smp_relDec-2024.txt\n",
            "-rw------- 1 root root 20683108218 Jan 29 02:09 ebd_US_rthhum_197401_202412_smp_relDec-2024_sampling.txt\n",
            "-rw------- 1 root root        6171 Jan 29 03:27 robert.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype_dict = {\n",
        "    'GLOBAL UNIQUE IDENTIFIER': 'str',\n",
        "    'TAXONOMIC ORDER': 'str',\n",
        "    'CATEGORY': 'str',\n",
        "    'TAXON CONCEPT ID': 'str',\n",
        "    'COMMON NAME': 'str',\n",
        "    'SCIENTIFIC NAME': 'str',\n",
        "    'SUBSPECIES COMMON NAME': 'str',\n",
        "    'SUBSPECIES SCIENTIFIC NAME': 'str',\n",
        "    'EXOTIC CODE': 'str',\n",
        "    'OBSERVATION COUNT': 'str',\n",
        "    'BREEDING CODE': 'str',\n",
        "    'BREEDING CATEGORY': 'str',\n",
        "    'BEHAVIOR CODE': 'str',\n",
        "    'AGE/SEX': 'str',\n",
        "    'COUNTRY': 'str',\n",
        "    'COUNTRY CODE': 'str',\n",
        "    'STATE': 'str',\n",
        "    'STATE CODE': 'str',\n",
        "    'COUNTY': 'str',\n",
        "    'COUNTY CODE': 'str',\n",
        "    'IBA CODE': 'str',\n",
        "    'BCR CODE': 'str',\n",
        "    'USFWS CODE': 'str',\n",
        "    'ATLAS BLOCK': 'str',\n",
        "    'LOCALITY': 'str',\n",
        "    'LOCALITY ID': 'str',\n",
        "    'LOCALITY TYPE': 'str',\n",
        "    'LATITUDE': 'str',\n",
        "    'LONGITUDE': 'str',\n",
        "    'OBSERVATION DATE': 'str',\n",
        "    'TIME OBSERVATIONS STARTED': 'str',\n",
        "    'OBSERVER ID': 'str',\n",
        "    'SAMPLING EVENT IDENTIFIER': 'str',\n",
        "    'PROTOCOL TYPE': 'str',\n",
        "    'PROTOCOL CODE': 'str',\n",
        "    'PROJECT CODE': 'str',\n",
        "    'DURATION MINUTES': 'str',\n",
        "    'EFFORT DISTANCE KM': 'str',\n",
        "    'EFFORT AREA HA': 'str',\n",
        "    'NUMBER OBSERVERS': 'str',\n",
        "    'ALL SPECIES REPORTED': 'str',\n",
        "    'GROUP IDENTIFIER': 'str',\n",
        "    'HAS MEDIA': 'str',\n",
        "    'APPROVED': 'str',\n",
        "    'REVIEWED': 'str',\n",
        "    'REASON': 'str',\n",
        "    'TRIP COMMENTS': 'str',\n",
        "    'SPECIES COMMENTS': 'str'\n",
        "}"
      ],
      "metadata": {
        "id": "J2yAuag6D4CH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the dtype dictionary without 'LAST EDITED DATE'\n",
        "# since we will handle it with parse_dates\n",
        "dtype_dict = {\n",
        "    'GLOBAL UNIQUE IDENTIFIER': 'str',\n",
        "    'TAXONOMIC ORDER': 'str',\n",
        "    'CATEGORY': 'str',\n",
        "    'TAXON CONCEPT ID': 'str',\n",
        "    'COMMON NAME': 'str',\n",
        "    'SCIENTIFIC NAME': 'str',\n",
        "    'SUBSPECIES COMMON NAME': 'str',\n",
        "    'SUBSPECIES SCIENTIFIC NAME': 'str',\n",
        "    'EXOTIC CODE': 'str',\n",
        "    'OBSERVATION COUNT': 'str',\n",
        "    'BREEDING CODE': 'str',\n",
        "    'BREEDING CATEGORY': 'str',\n",
        "    'BEHAVIOR CODE': 'str',\n",
        "    'AGE/SEX': 'str',\n",
        "    'COUNTRY': 'str',\n",
        "    'COUNTRY CODE': 'str',\n",
        "    'STATE': 'str',\n",
        "    'STATE CODE': 'str',\n",
        "    'COUNTY': 'str',\n",
        "    'COUNTY CODE': 'str',\n",
        "    'IBA CODE': 'str',\n",
        "    'BCR CODE': 'str',\n",
        "    'USFWS CODE': 'str',\n",
        "    'ATLAS BLOCK': 'str',\n",
        "    'LOCALITY': 'str',\n",
        "    'LOCALITY ID': 'str',\n",
        "    'LOCALITY TYPE': 'str',\n",
        "    'LATITUDE': 'str',\n",
        "    'LONGITUDE': 'str',\n",
        "    'OBSERVATION DATE': 'str',\n",
        "    'TIME OBSERVATIONS STARTED': 'str',\n",
        "    'OBSERVER ID': 'str',\n",
        "    'SAMPLING EVENT IDENTIFIER': 'str',\n",
        "    'PROTOCOL TYPE': 'str',\n",
        "    'PROTOCOL CODE': 'str',\n",
        "    'PROJECT CODE': 'str',\n",
        "    'DURATION MINUTES': 'str',\n",
        "    'EFFORT DISTANCE KM': 'str',\n",
        "    'EFFORT AREA HA': 'str',\n",
        "    'NUMBER OBSERVERS': 'str',\n",
        "    'ALL SPECIES REPORTED': 'str',\n",
        "    'GROUP IDENTIFIER': 'str',\n",
        "    'HAS MEDIA': 'str',\n",
        "    'APPROVED': 'str',\n",
        "    'REVIEWED': 'str',\n",
        "    'REASON': 'str',\n",
        "    'TRIP COMMENTS': 'str',\n",
        "    'SPECIES COMMENTS': 'str'\n",
        "}\n",
        "\n",
        "# Read the file in chunks\n",
        "chunksize = 10000  # Adjust this based on memory availability\n",
        "chunk_list = []\n",
        "\n",
        "for chunk in pd.read_csv(\n",
        "      #'robert.dat'\n",
        "      'ebd_US_rthhum_197401_202412_smp_relDec-2024_sampling.txt'\n",
        "      , sep='\\t'\n",
        "      , chunksize=chunksize\n",
        "      ,dtype=dtype_dict\n",
        "      ,parse_dates=['LAST EDITED DATE']  # Convert to datetime directly\n",
        "      ,on_bad_lines='warn'  # Print a warning for bad lines\n",
        "      ):\n",
        "\n",
        "\n",
        "    chunk_list.append(chunk)  # Process each chunk here if needed\n",
        "\n",
        "# Combine all chunks if needed (Optional)\n",
        "bird_data = pd.concat(chunk_list, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "# Use parse_dates to handle 'LAST EDITED DATE'\n",
        "#bird_data = pd.read_csv(\n",
        "#    ,sep='\\t'\n",
        "#    ,dtype=dtype_dict\n",
        "#    ,parse_dates=['LAST EDITED DATE']  # Convert to datetime directly\n",
        "#    ,on_bad_lines='warn'  # Print a warning for bad lines\n",
        "#    ,error_bad_lines=False  # Skip bad lines\n",
        "#)\n",
        "\n",
        "\n",
        "# Verify the data type and display the earliest date\n",
        "print(bird_data['LAST EDITED DATE'].dtype)  # Should show datetime64[ns]\n",
        "print(\"Earliest Last Edited Date:\", bird_data['LAST EDITED DATE'].min())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "QZeK58HbMgC_",
        "outputId": "0611b2fc-486f-4288-90ad-925683258cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-53c79451b3d5>:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  for chunk in pd.read_csv(\n",
            "<ipython-input-4-53c79451b3d5>:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  for chunk in pd.read_csv(\n",
            "<ipython-input-4-53c79451b3d5>:60: ParserWarning: Skipping line 14218111: expected 31 fields, saw 49\n",
            "\n",
            "  for chunk in pd.read_csv(\n",
            "<ipython-input-4-53c79451b3d5>:60: ParserWarning: Skipping line 14395830: expected 31 fields, saw 49\n",
            "\n",
            "  for chunk in pd.read_csv(\n",
            "<ipython-input-4-53c79451b3d5>:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  for chunk in pd.read_csv(\n",
            "<ipython-input-4-53c79451b3d5>:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  for chunk in pd.read_csv(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<=' not supported between instances of 'Timestamp' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-53c79451b3d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Verify the data type and display the earliest date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbird_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LAST EDITED DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should show datetime64[ns]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Earliest Last Edited Date:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbird_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LAST EDITED DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6505\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m     ):\n\u001b[0;32m-> 6507\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6509\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12386\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12387\u001b[0m     ):\n\u001b[0;32m> 12388\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  12389\u001b[0m             \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12390\u001b[0m             \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12377\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  12378\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12379\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6455\u001b[0m                     \u001b[0;34m\"with non-numeric dtypes.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6456\u001b[0m                 )\n\u001b[0;32m-> 6457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6459\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"any\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mreduction\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value_typ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         )\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_null_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     44\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'Timestamp' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define chunk size\n",
        "chunksize = 100000  # Adjust as needed\n",
        "chunk_list = []\n",
        "\n",
        "# Read file in chunks\n",
        "for chunk in pd.read_csv(\n",
        "      'ebd_US_rthhum_197401_202412_smp_relDec-2024_sampling.txt'\n",
        "      , sep='\\t'\n",
        "      , chunksize=chunksize\n",
        "      , dtype=dtype_dict\n",
        "      , on_bad_lines='warn'  # Print a warning for bad lines\n",
        "    ):\n",
        "\n",
        "    # Ensure 'LAST EDITED DATE' is converted properly\n",
        "    chunk['LAST EDITED DATE'] = pd.to_datetime(chunk['LAST EDITED DATE'], errors='coerce')\n",
        "\n",
        "    # Append cleaned chunk\n",
        "    chunk_list.append(chunk)\n",
        "\n",
        "# Combine chunks into a single DataFrame\n",
        "bird_data = pd.concat(chunk_list, ignore_index=True)\n",
        "\n",
        "# Drop NaT values before finding min date (if necessary)\n",
        "bird_data = bird_data.dropna(subset=['LAST EDITED DATE'])\n",
        "\n",
        "# Verify the data type\n",
        "print(\"Data Type of 'LAST EDITED DATE':\", bird_data['LAST EDITED DATE'].dtype)\n",
        "\n",
        "# Get the earliest date\n",
        "min_date = bird_data['LAST EDITED DATE'].min()\n",
        "print(\"Earliest Last Edited Date:\", min_date)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ODb4YWLKAIY",
        "outputId": "8e5d89cb-3235-43cb-8e15-43ba94b24f2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d84d962ffb68>:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  chunk['LAST EDITED DATE'] = pd.to_datetime(chunk['LAST EDITED DATE'], errors='coerce')\n",
            "<ipython-input-6-d84d962ffb68>:8: ParserWarning: Skipping line 14218111: expected 31 fields, saw 49\n",
            "\n",
            "  for chunk in pd.read_csv(\n",
            "<ipython-input-6-d84d962ffb68>:8: ParserWarning: Skipping line 14395830: expected 31 fields, saw 49\n",
            "\n",
            "  for chunk in pd.read_csv(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Type of 'LAST EDITED DATE': datetime64[ns]\n",
            "Earliest Last Edited Date: 2002-05-13 21:50:05\n"
          ]
        }
      ]
    }
  ]
}